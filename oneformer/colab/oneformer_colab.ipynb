{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# üéóÔ∏è **OneFormer: One Transformer to Rule Universal Image Segmentation** üéóÔ∏è\n",
    "\n",
    "## CVPR 2023\n",
    "\n",
    "[[`Project Page`](https://praeclarumjj3.github.io/oneformer/)] [[`arXiv`](https://arxiv.org/abs/2211.06220)] [[`GitHub`](https://github.com/SHI-Labs/OneFormer)] [[`HuggingFace Space`](https://huggingface.co/spaces/shi-labs/OneFormer)] [[`HuggingFace transformers`](https://huggingface.co/docs/transformers/main/en/model_doc/oneformer)]\n",
    "\n",
    "![Teaser](https://praeclarumjj3.github.io/oneformer/teaser.svg)\n",
    "\n",
    "#### OneFormer is the **first** multi-task universal image segmentation framework based on transformers. OneFormer needs to be trained only once with a single universal architecture, a single model, and on a single dataset , to outperform existing frameworks across semantic, instance, and panoptic segmentation tasks!\n",
    "\n",
    "\n",
    "\n",
    "This notebook provides a quickstart guide to using OneFormer for inference on images. We hope OneFormer inspires more research into developing train-once universal image segmentation frameworks. ‚úå"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df70JDWc13OQ"
   },
   "source": [
    "#### If you found OneFormer useful in your research, please consider starring ‚≠ê us on [[`GitHub`](https://github.com/SHI-Labs/OneFormer)] and citing üìö us in your research!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoYYWnCuVaWU"
   },
   "source": [
    "# Setup OneFormer Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUmK767kWQlq",
    "outputId": "56fe6b50-65df-4068-c561-86ae1d957acb"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title 1. Clone OneFormer Repo\n",
    "######\n",
    "%cd /content/\n",
    "!rm -rf OneFormer/\n",
    "!git clone https://github.com/SHI-Labs/OneFormer-Colab.git\n",
    "! mv OneFormer-Colab OneFormer\n",
    "%cd /content/OneFormer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzVUqlOwHOBa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ad15d73-480c-4042-d85f-196f4afbf41d"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title 2. Install Dependencies. \n",
    "#@markdown It may take several minutes for all installations to finish.\n",
    "######\n",
    "\n",
    "# # Install opencv (required for running the demo)\n",
    "!pip3 install -U opencv-python --quiet\n",
    "!pip3 install natten -f https://shi-labs.com/natten/wheels/cu113/torch1.10.1/index.html --quiet\n",
    "\n",
    "# # # Install other dependencies\n",
    "!pip3 install git+https://github.com/cocodataset/panopticapi.git --quiet\n",
    "!pip3 install git+https://github.com/mcordts/cityscapesScripts.git --quiet\n",
    "\n",
    "!pip3 install -r requirements.txt --quiet\n",
    "!pip3 install ipython-autotime --quiet\n",
    "!pip3 install imutils --quiet"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sys, os, distutils.core\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])} --quiet\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDg7op2CuaFX",
    "outputId": "28903c3d-edad-40fe-d4a2-3da792dc287f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw41v_NH8vM9"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title 3. Import Libraries and other Utilities\n",
    "######\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "setup_logger(name=\"oneformer\")\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from google.colab.patches import cv2_imshow\n",
    "import imutils\n",
    "\n",
    "# Import detectron2 utilities\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from detectron2.data import MetadataCatalog\n",
    "from demo.defaults import DefaultPredictor\n",
    "from demo.visualizer import Visualizer, ColorMode\n",
    "\n",
    "\n",
    "# import OneFormer Project\n",
    "from oneformer import (\n",
    "    add_oneformer_config,\n",
    "    add_common_config,\n",
    "    add_swin_config,\n",
    "    add_dinat_config,\n",
    "    add_convnext_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLH-GzQCxw53"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title 4. Define helper functions\n",
    "######\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "SWIN_CFG_DICT = {\"cityscapes\": \"configs/cityscapes/oneformer_swin_large_IN21k_384_bs16_90k.yaml\",\n",
    "            \"coco\": \"configs/coco/oneformer_swin_large_IN21k_384_bs16_100ep.yaml\",\n",
    "            \"ade20k\": \"configs/ade20k/oneformer_swin_large_IN21k_384_bs16_160k.yaml\",}\n",
    "\n",
    "DINAT_CFG_DICT = {\"cityscapes\": \"configs/cityscapes/oneformer_dinat_large_bs16_90k.yaml\",\n",
    "            \"coco\": \"configs/coco/oneformer_dinat_large_bs16_100ep.yaml\",\n",
    "            \"ade20k\": \"configs/ade20k/oneformer_dinat_large_IN21k_384_bs16_160k.yaml\",}\n",
    "\n",
    "def setup_cfg(dataset, model_path, use_swin):\n",
    "    # load config from file and command-line arguments\n",
    "    cfg = get_cfg()\n",
    "    add_deeplab_config(cfg)\n",
    "    add_common_config(cfg)\n",
    "    add_swin_config(cfg)\n",
    "    add_dinat_config(cfg)\n",
    "    add_convnext_config(cfg)\n",
    "    add_oneformer_config(cfg)\n",
    "    if use_swin:\n",
    "      cfg_path = SWIN_CFG_DICT[dataset]\n",
    "    else:\n",
    "      cfg_path = DINAT_CFG_DICT[dataset]\n",
    "    cfg.merge_from_file(cfg_path)\n",
    "    cfg.MODEL.DEVICE = 'cpu'\n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "    cfg.freeze()\n",
    "    return cfg\n",
    "\n",
    "def setup_modules(dataset, model_path, use_swin):\n",
    "    cfg = setup_cfg(dataset, model_path, use_swin)\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    metadata = MetadataCatalog.get(\n",
    "        cfg.DATASETS.TEST_PANOPTIC[0] if len(cfg.DATASETS.TEST_PANOPTIC) else \"__unused\"\n",
    "    )\n",
    "    if 'cityscapes_fine_sem_seg_val' in cfg.DATASETS.TEST_PANOPTIC[0]:\n",
    "        from cityscapesscripts.helpers.labels import labels\n",
    "        stuff_colors = [k.color for k in labels if k.trainId != 255]\n",
    "        metadata = metadata.set(stuff_colors=stuff_colors)\n",
    "    \n",
    "    return predictor, metadata\n",
    "\n",
    "def panoptic_run(img, predictor, metadata):\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
    "    predictions = predictor(img, \"panoptic\")\n",
    "    panoptic_seg, segments_info = predictions[\"panoptic_seg\"]\n",
    "    out = visualizer.draw_panoptic_seg_predictions(\n",
    "    panoptic_seg.to(cpu_device), segments_info, alpha=0.5\n",
    ")\n",
    "    return out\n",
    "\n",
    "def instance_run(img, predictor, metadata):\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
    "    predictions = predictor(img, \"instance\")\n",
    "    instances = predictions[\"instances\"].to(cpu_device)\n",
    "    out = visualizer.draw_instance_predictions(predictions=instances, alpha=0.5)\n",
    "    return out\n",
    "\n",
    "def semantic_run(img, predictor, metadata):\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
    "    predictions = predictor(img, \"semantic\")\n",
    "    out = visualizer.draw_sem_seg(\n",
    "        predictions[\"sem_seg\"].argmax(dim=0).to(cpu_device), alpha=0.5\n",
    "    )\n",
    "    return out\n",
    "\n",
    "TASK_INFER = {\"panoptic\": panoptic_run, \n",
    "              \"instance\": instance_run, \n",
    "              \"semantic\": semantic_run}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk4gID50K03a"
   },
   "source": [
    "# Run Inference using OneFormer on CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgKyUL4pngvE"
   },
   "source": [
    "## ADE20K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "xX8TLytOVal8"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@markdown We use `DiNAT-L` as the default backbone. To use Swin-L as backbone, select the checkbox below.\n",
    "use_swin = False #@param {type: 'boolean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Ldq3OJUzVl2",
    "outputId": "439c2399-bb49-4c53-d306-7c4a56059873"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title A. Initialize Model\n",
    "######\n",
    "# download model checkpoint\n",
    "import os\n",
    "import subprocess\n",
    "if not use_swin:\n",
    "  if not os.path.exists(\"250_16_dinat_l_oneformer_ade20k_160k.pth\"):\n",
    "    subprocess.run('wget https://shi-labs.com/projects/oneformer/ade20k/250_16_dinat_l_oneformer_ade20k_160k.pth', shell=True)\n",
    "  predictor, metadata = setup_modules(\"ade20k\", \"250_16_dinat_l_oneformer_ade20k_160k.pth\", use_swin)\n",
    "else:\n",
    "  if not os.path.exists(\"250_16_swin_l_oneformer_ade20k_160k.pth\"):\n",
    "    subprocess.run('wget https://shi-labs.com/projects/oneformer/ade20k/250_16_swin_l_oneformer_ade20k_160k.pth', shell=True)\n",
    "  predictor, metadata = setup_modules(\"ade20k\", \"250_16_swin_l_oneformer_ade20k_160k.pth\", use_swin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "dq9GY37ml1kr",
    "outputId": "01895fc1-3794-44cb-b32b-b9bbcf7be6a2"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title B. Display Sample Image. You can modify the path and try your own images!\n",
    "######\n",
    "\n",
    "# change path here for another image\n",
    "img = cv2.imread(\"samples/ade20k.jpeg\")\n",
    "img = imutils.resize(img, width=640)\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "HUjkwRsOn1O0",
    "outputId": "1640081f-76ee-4f9e-ed0a-873b9684fdb0"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title C. Run Inference (CPU)\n",
    "#@markdown Specify the **task**. `Default: panoptic`. Execution may take upto 2 minutes\n",
    "######\n",
    "###### Specify Task Here ######\n",
    "task = \"panoptic\" #@param\n",
    "##############################\n",
    "%load_ext autotime\n",
    "out = TASK_INFER[task](img, predictor, metadata).get_image()\n",
    "cv2_imshow(out[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyKgDthKDTVt"
   },
   "source": [
    "## Cityscapes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvWKWrl8V_4_",
    "outputId": "f5423ee6-1651-41de-9a2a-687fd40fee3b"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@markdown We use `DiNAT-L` as the default backbone. To use Swin-L as backbone, select the checkbox below.\n",
    "use_swin = False #@param {type: 'boolean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cek_0PhgDTV1",
    "outputId": "0f5b85b8-b522-4b94-d3ac-488872749046"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title A. Initialize Model\n",
    "######\n",
    "# download model checkpoint\n",
    "import os\n",
    "import subprocess\n",
    "if not use_swin:\n",
    "  if not os.path.exists(\"250_16_dinat_l_oneformer_cityscapes_90k.pth\"):\n",
    "    subprocess.run('wget https://shi-labs.com/projects/oneformer/cityscapes/250_16_dinat_l_oneformer_cityscapes_90k.pth', shell=True)\n",
    "  predictor, metadata = setup_modules(\"cityscapes\", \"250_16_dinat_l_oneformer_cityscapes_90k.pth\", use_swin)\n",
    "else:\n",
    "  if not os.path.exists(\"250_16_swin_l_oneformer_cityscapes_90k.pth\"):\n",
    "    subprocess.run('wget https://shi-labs.com/projects/oneformer/cityscapes/250_16_swin_l_oneformer_cityscapes_90k.pth', shell=True)\n",
    "  predictor, metadata = setup_modules(\"cityscapes\", \"250_16_swin_l_oneformer_cityscapes_90k.pth\", use_swin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "jvkqpNdBDTV2",
    "outputId": "88e0d7a1-1fe3-4fc4-b530-1aff180682cc"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title B. Display Sample Image. You can modify the path and try your own images!\n",
    "######\n",
    "\n",
    "# change path here for another image\n",
    "img = cv2.imread(\"samples/cityscapes.png\")\n",
    "img = imutils.resize(img, width=512)\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "CPqny7PmDTV2",
    "outputId": "9508a077-83df-41f2-a7ad-8f52b85cc86d"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title C. Run Inference (CPU)\n",
    "#@markdown Specify the **task**. `Default: panoptic`. Execution may take upto 2 minutes\n",
    "######\n",
    "task = \"panoptic\" #@param\n",
    "%load_ext autotime\n",
    "out = TASK_INFER[task](img, predictor, metadata).get_image()\n",
    "cv2_imshow(out[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lowI8uz4Qep9"
   },
   "source": [
    "## COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "867pk7CoWCHl",
    "outputId": "bc9595e9-f1bf-4603-84d9-fd2f2cf2a271"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@markdown We use `DiNAT-L` as the default backbone. To use Swin-L as backbone, select the checkbox below.\n",
    "use_swin = False #@param {type: 'boolean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfggTxANQeqF",
    "outputId": "38fa9bab-dd68-4d78-cfca-809a12995272"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title A. Initialize Model\n",
    "######\n",
    "# download model checkpoint\n",
    "import os\n",
    "import subprocess\n",
    "if not use_swin:\n",
    "  if not os.path.exists(\"150_16_dinat_l_oneformer_coco_100ep.pth\"):\n",
    "    subprocess.run('wget https://shi-labs.com/projects/oneformer/coco/150_16_dinat_l_oneformer_coco_100ep.pth', shell=True)\n",
    "  predictor, metadata = setup_modules(\"coco\", \"150_16_dinat_l_oneformer_coco_100ep.pth\", use_swin)\n",
    "else:\n",
    "  if not os.path.exists(\"150_16_swin_l_oneformer_coco_100ep.pth\"):\n",
    "    subprocess.run('wget https://shi-labs.com/projects/oneformer/coco/150_16_swin_l_oneformer_coco_100ep.pth', shell=True)\n",
    "  predictor, metadata = setup_modules(\"coco\", \"150_16_swin_l_oneformer_coco_100ep.pth\", use_swin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "cyj_hdt9QeqG",
    "outputId": "3927f4ee-3b96-432c-a7a1-b295e644f48f"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title B. Display Sample Image. You can modify the path and try your own images!\n",
    "######\n",
    "\n",
    "# change path here for another image\n",
    "img = cv2.imread(\"samples/coco.jpeg\")\n",
    "img = imutils.resize(img, width=512)\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "Z2rD44_rQeqG",
    "outputId": "17ab303b-caa6-4aba-b0f6-ba106df4a35e"
   },
   "outputs": [],
   "source": [
    "######\n",
    "#@title C. Run Inference (CPU)\n",
    "#@markdown Specify the **task**. `Default: panoptic`. Execution may take upto 2 minutes\n",
    "######\n",
    "task = \"panoptic\" #@param\n",
    "%load_ext autotime\n",
    "out = TASK_INFER[task](img, predictor, metadata).get_image()\n",
    "cv2_imshow(out[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoZptOo2UNQ0"
   },
   "source": [
    "# More Information on OneFormer üéóÔ∏è\n",
    "- [Project Page](https://praeclarumjj3.github.io/oneformer/)\n",
    "- [GitHub Repo](https://SHI-Labs/OneFormer)\n",
    "- [ArXiv preprint](https://arxiv.org/abs/2211.06220)\n",
    "- [HuggingFace Space](https://huggingface.co/spaces/shi-labs/OneFormer)\n",
    "- [HuggingFace transformers](https://huggingface.co/docs/transformers/main/en/model_doc/oneformer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
